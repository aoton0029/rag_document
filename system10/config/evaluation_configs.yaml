# 評価設定ファイル
# 自動メトリクスと人手評価の設定

# 自動評価メトリクス
automatic_metrics:
  # テキスト類似性メトリクス
  rouge:
    enabled: true
    rouge_types: ["rouge1", "rouge2", "rougeL", "rougeLsum"]
    use_stemmer: true
    split_summaries: true
    
  bleu:
    enabled: false  # 必要時のみ
    max_order: 4
    smooth: false
    
  bert_score:
    enabled: true
    model_type: "bert-base-multilingual-cased"
    num_layers: 9
    verbose: false
    idf: false
    device: "auto"
    batch_size: 64
    
  # QA特化メトリクス
  exact_match:
    enabled: true
    normalize_answer: true
    ignore_punctuation: true
    ignore_case: true
    ignore_articles: ["a", "an", "the", "の", "は", "が", "を"]
    
  f1_score:
    enabled: true
    normalize_answer: true
    tokenization_method: "word"  # word, character
    
  # セマンティック類似性
  semantic_similarity:
    enabled: true
    model: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    similarity_function: "cosine"  # cosine, dot_product
    threshold: 0.7
    
# 検索評価メトリクス
retrieval_metrics:
  recall_at_k:
    enabled: true
    k_values: [1, 3, 5, 10, 20]
    
  precision_at_k:
    enabled: true
    k_values: [1, 3, 5, 10, 20]
    
  mrr:  # Mean Reciprocal Rank
    enabled: true
    
  ndcg:  # Normalized Discounted Cumulative Gain
    enabled: true
    k_values: [1, 3, 5, 10]
    
  map_score:  # Mean Average Precision
    enabled: true

# RAG特化評価
rag_specific_metrics:
  # Ragas統合
  ragas_metrics:
    enabled: true
    metrics:
      - "answer_relevancy"
      - "faithfulness"
      - "context_precision"
      - "context_recall"
      - "context_relevancy"
    llm_model: "gpt-3.5-turbo"  # Ragas用LLM
    embeddings_model: "text-embedding-ada-002"
    
  # カスタムメトリクス
  hallucination_detection:
    enabled: true
    method: "contradiction_detection"
    threshold: 0.8
    
  source_attribution:
    enabled: true
    require_citations: false
    citation_format: "numbered"  # numbered, named, none
    
  answer_completeness:
    enabled: true
    completeness_threshold: 0.7

# 人手評価設定
human_evaluation:
  enabled: true
  
  # 評価項目
  criteria:
    accuracy:
      scale: 5  # 1-5点
      description: "回答の正確性"
      
    relevance:
      scale: 5
      description: "質問との関連性"
      
    completeness:
      scale: 5
      description: "回答の完全性"
      
    clarity:
      scale: 5
      description: "回答の明確性"
      
    redundancy:
      scale: 3  # 1: 冗長, 2: 適切, 3: 簡潔
      description: "冗長性"
      
  # 評価者設定
  evaluators:
    required_evaluators: 2
    inter_annotator_agreement: true
    agreement_threshold: 0.7
    
  # 評価UI設定
  ui_config:
    show_source_documents: true
    show_retrieval_score: true
    show_query_context: true
    randomize_order: true
    
  # 出力設定
  output:
    format: ["csv", "json"]
    include_comments: true
    include_timestamps: true

# ファクトチェック設定
fact_checking:
  enabled: false  # 高度な機能として
  
  external_knowledge_bases:
    wikipedia:
      enabled: false
      api_endpoint: "https://ja.wikipedia.org/api/rest_v1/"
      
    custom_kb:
      enabled: false
      connection_string: ""
      
  fact_verification:
    method: "entailment_detection"
    model: "microsoft/deberta-large-mnli"
    threshold: 0.8

# メトリクス収集設定
metrics_collection:
  # 実行時メトリクス
  runtime_metrics:
    track_latency: true
    track_memory_usage: true
    track_token_usage: true
    track_api_calls: true
    
  # 品質メトリクス
  quality_metrics:
    consistency_across_runs: true
    stability_over_time: true
    error_rate_tracking: true

# 結果保存設定
result_storage:
  # 保存形式
  formats:
    json:
      enabled: true
      pretty_print: true
      include_metadata: true
      
    csv:
      enabled: true
      include_headers: true
      separator: ","
      
    parquet:
      enabled: false
      compression: "snappy"
      
  # ファイル構成
  file_structure:
    base_dir: "./results"
    run_subdirs: true
    timestamp_format: "%Y%m%d_%H%M%S"
    
  # メタデータ
  metadata:
    include_config_snapshot: true
    include_system_info: true
    include_git_commit: true
    include_dependencies: true

# デフォルト評価設定
default_evaluation:
  automatic_metrics: ["rouge", "bert_score", "exact_match", "f1_score"]
  retrieval_metrics: ["recall_at_k", "precision_at_k", "mrr"]
  human_evaluation: false
  
# 実験パターン別評価設定
experiment_evaluation_patterns:
  pattern_1:
    name: "basic_metrics"
    automatic_metrics: ["rouge", "exact_match"]
    retrieval_metrics: ["recall_at_k"]
    
  pattern_2:
    name: "comprehensive_auto"
    automatic_metrics: ["rouge", "bert_score", "exact_match", "f1_score", "semantic_similarity"]
    retrieval_metrics: ["recall_at_k", "precision_at_k", "mrr", "ndcg"]
    
  pattern_3:
    name: "rag_focused"
    automatic_metrics: ["bert_score", "semantic_similarity"]
    retrieval_metrics: ["recall_at_k", "precision_at_k", "mrr"]
    rag_specific_metrics: ["ragas_metrics"]
    
  pattern_4:
    name: "human_validation"
    automatic_metrics: ["rouge", "exact_match"]
    human_evaluation: true
    
  pattern_5:
    name: "production_ready"
    automatic_metrics: ["rouge", "bert_score", "exact_match", "f1_score"]
    retrieval_metrics: ["recall_at_k", "precision_at_k", "mrr"]
    rag_specific_metrics: ["ragas_metrics"]
    human_evaluation: true

# A/Bテスト設定
ab_testing:
  enabled: false
  
  test_configuration:
    control_group_size: 0.5
    statistical_significance_threshold: 0.05
    minimum_sample_size: 100
    
  metrics_focus:
    primary_metric: "f1_score"
    secondary_metrics: ["rouge", "bert_score"]

# レポート生成設定
reporting:
  auto_generate: true
  
  report_types:
    summary:
      enabled: true
      include_charts: true
      
    detailed:
      enabled: true
      include_error_analysis: true
      
    comparison:
      enabled: true
      baseline_run_id: null
      
  export_formats: ["html", "pdf", "markdown"]
  
# 評価データ管理
evaluation_data:
  # 評価用データセット
  datasets:
    validation_set:
      path: "./data/evaluation/validation.json"
      format: "json"
      required_fields: ["query", "expected_answer", "context"]
      
    test_set:
      path: "./data/evaluation/test.json"
      format: "json"
      required_fields: ["query", "expected_answer"]
      
  # データ品質チェック
  quality_checks:
    check_duplicates: true
    validate_format: true
    check_missing_values: true
    
# パフォーマンス設定
performance:
  parallel_evaluation: true
  max_workers: 4
  batch_size: 50
  timeout_per_evaluation: 60
  
# エラーハンドリング
error_handling:
  continue_on_error: true
  max_retries: 3
  log_errors: true
  partial_results: true