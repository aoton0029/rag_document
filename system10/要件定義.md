# 概要
llama_indexを用いたRAGシステムの評価フレームワーク。
チャンキングから評価までを一つの試行として、チャンキング・インデクシング手法、AdvancedRAG手法の組み合わせによる試行パターンを作り評価する。
テストパターンごとの評価結果を比較することで、チャンキング/インデクシングの最適手法およびAdvancedRAGの最適化を目指す。

# 目的
- 自動化された実験フレームワークで複数手法を系統的に比較し、最適構成を特定する。
- 再現性のある評価プロセスを確立し、結果を定量的に保存・可視化する。
- 論文PDF・製品マニュアルPDFを主対象とし、実運用に近い条件での精度を評価する。

# 対象データ
- 論文PDF、製品マニュアルPDF（メタ情報を含む）
- 前処理: 言語（日本語優先）、メタデータ抽出

# 要件
## 機能要件
- データ取り込み（PDF読み取り、メタ抽出）
- チャンキング（複数手法の適用）
- トークナイズとトークン長制御
- 埋め込み生成（複数embedding backends対応）
- ベクトルストア/ドキュメントストア/インデックスの組合せ運用
- RAG実行（retriever + generator、AdvancedRAG設定適用）
- 評価モジュール（自動指標と人手評価準備）
- 実験ランナー（設定ファイルによる完全自動実行、ランID管理）
- 結果保存と可視化（CSV/JSON/図）

## 非機能要件
- 再現性: seed固定、設定ファイル完全保存
- 拡張性: 新しいチャンキング/モデル追加が容易
- スケーラビリティ: 並列実行、バッチ処理対応
- ログと監視: 実験ログ、メトリクスの時系列保存
- セキュリティ: 機密データ取り扱い時の暗号化/アクセス制御

# 実験設計（推奨）
- 因子（例）
  - チャンキング手法: 固定長トークン, セマンティックセグメント, 見出しベース, レイアウトベース
  - インデックス/ベクトルストア: Milvus, Faiss, RedisIndexStore
  - Embeddingモデル: qwen3-embedding:8b(Ollama), sentence-transformers variants
  - LLM: Qwen/Qwen3-32B, openai/gpt-oss-120b
  - AdvancedRAGパラメータ: prompt templates, context window, reranker有無
- 実験パターン: 全因子実験（可能であれば）, 制約ある場合は部分因子（Taguchiやランダム探索）
- 試行単位: 1ドキュメント×1設定での出力を1試行として集計

# 評価指標
- 自動メトリクス: ROUGE, BLEU（必要時）, BERTScore, Exact Match (EM), F1（QA向け）
- 検索指標: Recall@k, MRR, Precision@k
- コヒーレンス/正確性: ファクトチェック（外部知識ベースとの照合）
- 人手評価: 理解度、正確性、冗長性（評価用UI/CSV出力を用意）
- メトリクス収集: 各試行にランIDを付けJSON+CSVで保存

# アーキテクチャ（コンポーネント）
- Data Ingestor: PDF reader → text + metadata。可能なら llama_index.readers の実装を使用。
- Chunker: NodeParser / TextSplitter をラップした抽象インターフェース（llama_index の Node/Chunk 単位を基準にする）。
- Tokenizer/Normalizer: PromptHelper を使ってトークンウィンドウ管理を行う。
- Embedding Service: llama_index の Embeddings インターフェース経由（例: OllamaEmbeddingAdapter）。
- VectorStore: Milvus (推奨) を llama_index.vector_stores 経由でアダプタ的に利用。
- DocStore: MongoDB を llama_index.docstores 経由で利用（StorageContext に統合）。
- IndexStore: RedisIndexStore（llama_index.storage.index_store）を推奨。
- Retriever: llama_index の Retriever API（similarity/hybrid/reranker）を直接利用し、retriever_args を設定ファイルで制御。
- RAG Engine: QueryEngine + ResponseSynthesizer（llama_index 的ワークフロー）を用い、LLMPredictor や ServiceContext で LLM / prompt を制御。
- Evaluator: 出力は既存の自動評価（ROUGE 等）。QueryEngine の出力ログをそのまま評価モジュールに流す。

# データフロー（簡略）
1. PDF → Data Ingestor → raw text + metadata
2. Chunker（選択）→ chunk list（id, text, meta, token_count）
3. Tokenizer → token counts（truncateルール適用）
4. Embedding Service → vectors
5. VectorStore/DocStoreへ保存（StorageContext設定に基づく）
6. RAG実行（Retriever → Context組成 → LLM呼出）
7. 評価モジュールで出力評価、結果保存

# 設定管理
- 設定ファイル: YAML（config/*.yaml）。llama_index 優先利用を反映したキー例:
  - service_context:
      llm: qwen3-32b
      llm_predictor_params:
        temperature: 0.0
        max_tokens: 1024
      prompt_helper_params:
        max_input_size: 4096
        num_output: 512
  - storage_context:
      vector_store:
        type: milvus
        connection: {...}
      docstore:
        type: mongodb
        connection: {...}
      index_store:
        type: redis
        connection: {...}
  - index:
      type: GPTVectorStoreIndex
      index_args: {...}
  - retriever_args:
      top_k: 10
      search_type: similarity
      reranker: true
  - embedding:
      backend: ollama
      model: qwen3-embedding:8b
- 実験実行: 実行時に使用した全設定（service_context, storage_context, index設定等）をスナップショットとして保存し、再現に必要な全ての llama_index 設定を含める。

# 実装ガイドライン（モジュール責務）
- llama_index の抽象（Node, StorageContext, ServiceContext, Index, Retriever, QueryEngine）を第一選択肢として設計する。
- 各機能（chunking/embedding/retrieval/llm）は llama_index のインターフェースをラップする実装を提供し、必要に応じて置換可能にする（Adapterパターン）。
- 具体的な推奨実装（例）
  - ドキュメント読み込み: SimpleDirectoryReader / PDFReader を利用し、独自前処理は NodeParser を通す。
  - インデックス作成: GPTVectorStoreIndex（または VectorStoreIndex）を使い、StorageContext に Milvus/MongoDB/Redis を注入。
  - RAG処理: RetrieverQueryEngine + ResponseSynthesizer を使い、LLMPredictor/PromptHelperで出力制御。
- 設定駆動: 全ての llama_index の主要パラメータは YAML で指定し、実験ランナーが ServiceContext/StorageContext を構築して実行。
- テスト: llama_index の小さなモックまたはミニデータセットでのE2Eテストを用意する。

# 運用・監視
- 実験メタデータとメトリクスはファイルに保存
- エラー率、成功率、平均実行時間を定期レポート

# デリバラブル & マイルストーン（例）
- 1週目: 基本パイプライン（PDF→Chunk→Embedding→VectorStore）MVP
- 2週目: RAG実行と自動評価メトリクス実装
- 3週目: 実験ランナー、複数手法の比較
- 4週目: 結果可視化・ドキュメント、最初の報告書

# プロジェクト構造（参照）
```
rag-evaluation-framework/
├── README.md
├── requirements.txt
├── config/
│   ├── chunking_configs.yaml
│   ├── embedding_configs.yaml
│   ├── llm_configs.yaml
│   ├── tokenizer_configs.yaml
│   ├── evaluation_configs.yaml
│   ├── domain_configs.yaml
│   └── test_patterns.yaml
├── src/
│   ├── __init__.py
│   ├── database/
│   │   ├── database_manager.py
│   │   ├── mongodb_client.py
│   │   ├── redis_client.py
│   │   ├── neo4j_client.py
│   │   └── milvus_client.py
│   ├── chunking/
│   ├── indexing/
│   ├── embedding/
│   ├── retrieval/
│   ├── evaluation/
│   ├── query/
│   ├── responsesynthesizer/
│   ├── data_generation/
│   ├── monitoring/
│   └── utils/
├── tests/
├── data/
└── results/
```

# 各ディレクトリ説明
## config
各種設定ファイルを格納。YAML形式で記述。
- chunking_configs.yaml: チャンキング設定
- embedding_configs.yaml: 埋め込みモデル設定
- llm_configs.yaml: LLMモデル設定
- tokenizer_configs.yaml: トークナイザー設定
- evaluation_configs.yaml: 評価設定
- domain_configs.yaml: ドメイン固有設定
- test_patterns.yaml: テストパターン設定

## database
各種データベースクライアント、データベース管理クラスを格納。
### database_manager.py
データベース接続管理クラスを実装。各種データベースクライアントを初期化し、接続管理を行う。
### mongodb_client.py
MongoDBクライアントクラスを実装。ドキュメントストアとして使用。
from llama_index.docstores.mongodb_docstore import MongoDBDocumentStore
### redis_client.py
Redisクライアントクラスを実装。インデックスストアとして使用。
from llama_index.index_stores.redis_index_store import RedisIndexStore
### neo4j_client.py
Neo4jクライアントクラスを実装。グラフストアとして使用。
from llama_index.graph_stores.neo4j_graph_store import Neo4jGraphStore
### milvus_client.py
Milvusクライアントクラスを実装。ベクトルストアとして使用。
from llama_index.vector_stores.milvus import MilvusVectorStore
### StorageContext
StorageContextを構築し、Settingsで指定する。
- vector_store: Milvus
- docstore: Mongodb
- index_store: Redis
- graph_store: Neo4j

## data_generation
```python
from llama_index.core.readers.file.base import SimpleDirectoryReader
from llama_index.readers.file import DocxReader, PDFReader, EpubReader, ImageReader, PandasExcelReader, VideoAudioReader, MarkdownReader
from llama_index.readers.database import DatabaseReader
from llama_index.readers.whisper import WhisperReader
from llama_index.readers.json import JSONReader
from llama_index.readers.obsidian import ObsidianReader
from llama_index.core.readers.string_iterable import StringIterableReader
import pymupdf4llm
```

## chunking
chunkingでimportするクラス
```python
from llama_index.core.node_parser import SimpleNodeParser, SentenceSplitter
from llama_index.core.text_splitter import TokenTextSplitter
from llama_index.core.extractors import (
 TitleExtractor, 
 KeywordExtractor, 
 SummaryExtractor, 
 DocumentContextExtractor, 
 QuestionsAnsweredExtractor
)
from llama_index.extractors.entity import EntityExtractor
```

## embedding
embeddingでimportするクラス
```python
from llama_index.core.embeddings import (
    OllamaEmbedding,
    LangchainEmbedding,
    HuggingFaceEmbedding,
)
```

## retrieval
retrievalでimportするクラス
```python
from llama_index.core.retrievers import (
    VectorIndexRetriever, 
    KeywordTableSimpleRetriever,
    SummaryIndexRetriever,
    RouterRetriever,
    TreeRootRetriever,
    TransformRetriever,
    QueryFusionRetriever,
    AutoMergingRetriever,
    RecursiveRetriever,
    TreeSelectLeafRetriever,
    SummaryIndexEmbeddingRetriever,
    VectorIndexAutoRetriever,
    VectorContextRetriever,
    KnowledgeGraphRAGRetriever
)
from llama_index.core.postprocessor import SimilarityPostprocessor, KeywordNodePostprocessor
```


## query
queryでimportするクラス
```python
from llama_index.core.query_engine import (
    BaseQueryEngine, SQLJoinQueryEngine, CustomQueryEngine, PandasQueryEngine, 
    RouterQueryEngine, RetryQueryEngine, MultiStepQueryEngine, 
    JSONalyzeQueryEngine, TransformQueryEngine, 
    SQLAutoVectorQueryEngine, RetrieverQueryEngine, SQLTableRetrieverQueryEngine, 
    ToolRetrieverRouterQueryEngine, SimpleMultiModalQueryEngine, 
    KnowledgeGraphQueryEngine, RetrieverRouterQueryEngine, RetrySourceQueryEngine,
)
from llama_index.core.tools import ToolMetadata, RetrieverTool, QueryEngineTool
from llama_index.core.selectors import (
    MultiSelection, SingleSelection, LLMSingleSelector, 
    LLMMultiSelector, EmbeddingSingleSelector, 
    PydanticMultiSelector, PydanticSingleSelector,
)
from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, FilterOperator, FilterCondition
from llama_index.core.response_synthesizers import get_response_synthesizer
```

## evaluation
evaluationでimportするクラス
```python
from llama_index.core.evaluation import (
    FaithfulnessEvaluator,
    RelevancyEvaluator,
    CorrectnessEvaluator,
    BatchEvalRunner
)
```

## responsesynthesizer
responsesynthesizerでimportするクラス
```python
from llama_index.core.response_synthesizers import (
    get_response_synthesizer, BaseSynthesizer, ResponseMode
)
from llama_index.core.schema import NodeWithScore, QueryBundle, TextNode
from llama_index.core.base.response.schema import Response
```

## indexing
indexingでimportするクラス
```python
from llama_index.core import (
  VectorStoreIndex, 
  SummaryIndex, 
  TreeIndex, 
  KeywordTableIndex, 
  KnowledgeGraphIndex,
  DocumentSummaryIndex
)
```


# requirements.txt
```txt
pyyaml
python-dotenv
tqdm
setuptools
pymilvus
redis
pymongo
neo4j
llama-index
llama-index-core
llama-index-llms-ollama
llama-index-llms-vllm
llama-index-embeddings-ollama
llama-index-embeddings-langchain
llama-index-vector-stores-milvus
llama-index-graph-stores-neo4j
llama-index-readers-file
llama-index-readers-json
llama-index-readers-mongodb
llama-index-readers-database
llama-index-readers-milvus
llama-index-readers-obsidian
llama-index-readers-whisper
llama-index-readers-graphdb-cypher
llama-index-storage-index-store-redis
llama-index-storage-docstore-mongodb
llama-index-storage-kvstore-redis
llama-index-tools-database
llama-index-tools-neo4j
llama-index-multi-modal-llms-ollama
llama-index-packs-neo4j-query-engine
llama-index-extractors-entity
llama-index-experimental
transformers
sentence-transformers
ragas
datasets
pandas
numpy
scikit-learn
matplotlib
seaborn
scipy
pyyaml
pytest
tqdm
evaluate
rouge-score
bert-score
tiktoken
langchain
nest-asyncio
torch
torchvision
torchaudio
accelerate
pytest
pytest-asyncio
pymupdf
pymupdf4llm
spacy
nltk
mecab-python3
statsmodels
openai
joblib
asyncio
psutil
```